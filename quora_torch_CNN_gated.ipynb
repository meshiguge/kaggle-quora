{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./processed_data/poswords.csv')\n",
    "# df_train = df_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('./train_org.csv',usecols=['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_pos = pd.read_csv('./processed_data/poswords_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_1=[]\n",
    "texts_2 =[]\n",
    "labels = []\n",
    "for q1,q2,is_dup in zip(df_train.question1_pos,df_train.question2_pos,df_label.is_duplicate):\n",
    "    texts_1.append(q1.strip('[]').split(', '))\n",
    "    texts_2.append(q2.strip('[]').split(', '))\n",
    "    labels.append(int(is_dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_1 =[]\n",
    "pos_2 =[]\n",
    "for q1,q2 in zip(df_train_pos.question1_pos,df_train_pos.question2_pos):\n",
    "    pos_1.append(q1.strip('[]').split(', '))\n",
    "    pos_2.append(q2.strip('[]').split(', '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(pos_1)):\n",
    "    try:\n",
    "        assert len(texts_1[i])==len(pos_1[i])\n",
    "        assert len(texts_2[i])==len(pos_2[i])\n",
    "    except:\n",
    "        print i\n",
    "        break\n",
    "#     assert len(texts_2[i])==len(pos_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import itertools\n",
    "def build_vocab(sentences, max_vocab=30000):\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    vocabulary_inv = []\n",
    "    vocabulary_inv.append(\"<PAD/>\")\n",
    "    vocabulary_inv.append(\"<mino/>\")\n",
    "    vocabulary_inv.extend([x[0] for x in word_counts.most_common(max_vocab)])\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    return [vocabulary, vocabulary_inv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocabulary, vocabulary_inv = build_vocab(test_texts_1+test_texts_2+texts_1+texts_2, max_vocab=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_pos, vocabulary_inv_pos = build_vocab(pos_1+pos_2, max_vocab=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# output = open('vacabulary_quora_pt.pkl', 'wb')\n",
    "# pickle.dump(vocabulary,output)\n",
    "# output.close()\n",
    "# output = open('vocabulary_inv_quora_pt.pkl', 'wb') \n",
    "# pickle.dump(vocabulary,output)\n",
    "# output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "output = open('vacabulary_quora_pt.pkl', 'r')\n",
    "vocabulary = pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_data(ques1,ques2,label,vocabulary):\n",
    "    mino_idx = vocabulary[\"<mino/>\"]\n",
    "    data_index = []\n",
    "    for q1,q2,dup in zip(ques1,ques2,label):\n",
    "        sentence1 = [vocabulary.get(word, mino_idx) for word in q1]\n",
    "        sentence2 = [vocabulary.get(word, mino_idx) for word in q2]\n",
    "        data_index.append([sentence1,sentence2,dup])\n",
    "    return data_index\n",
    "data_index = build_data(texts_1,texts_2,labels,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_pos_index = build_data(pos_1,pos_2,labels,vocabulary_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    assert len(data_index[i][1])==len(data_pos_index[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "EMBEDDING_FILE = '/home/zhangjinbin/research/GoogleNews-vectors-negative300.bin'\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE,binary=True)\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "nb_words = min(MAX_NB_WORDS, len(vocabulary))+1\n",
    "embedding_matrix = np.random.normal(loc=0,scale=0.1,size=[nb_words, EMBEDDING_DIM])\n",
    "for word, i in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(embedding_matrix)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class biRNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,hidden_size,output_size,n_layers = 2):\n",
    "        super(biRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size =output_size\n",
    "        self.embed= nn.Embedding(vocab_size,embedding_size)\n",
    "        self.gru= nn.GRU(input_size=self.embedding_size,\n",
    "                            hidden_size=self.hidden_size,\n",
    "                            num_layers = self.n_layers,\n",
    "                            batch_first =True,\n",
    "                            bidirectional = True)\n",
    "        self.da = 200\n",
    "        self.r = 200\n",
    "        self.fc1 = nn.Linear(100*4, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 2)\n",
    "        self.fcWs1 = nn.Linear(self.hidden_size*2, self.da)\n",
    "        self.fcWs2 = nn.Linear(self.da,self.r)\n",
    "        \n",
    "        self.conv1_3 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv1_5 = nn.Conv2d(1, 100,(5, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv1_7 = nn.Conv2d(1, 100,(7, 300), stride=(1, 300),padding=(2,0))\n",
    "#         self.conv2_3 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv2_5 = nn.Conv2d(1, 200,(5, 300), stride=(1, 300),padding=(1,0))\n",
    "        self.conv2_7 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv2_g = nn.Conv2d(1, 100,(3, 100), stride=(1, 100),padding=(1,0))\n",
    "        \n",
    "        self.fc_dedim_mul = nn.Linear(self.da*self.r,100)\n",
    "        self.fc_dedim_sub = nn.Linear(self.da*self.r,100)\n",
    "        self.fc_dedim_rep = nn.Linear(self.da*self.r,100)\n",
    "        #self.fc_gate = nn.Linear(self.hidden_size*2*self.r,self.r*self.hidden_size*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def conv_block(self,input_seq):\n",
    "        h1_rep3 = self.conv1_3(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "        h1_rep3_g = self.conv2_7(input_seq.unsqueeze(1)).squeeze(3)\n",
    "        h2_rep3 = torch.bmm(self.sigmoid(h1_rep3_g), h1_rep3)\n",
    "        \n",
    "#         h1_rep5 = self.self.conv1_5(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "#         h1_rep5_g = self.conv1_5(input_seq.unsqueeze(1)).squeeze(3)\n",
    "#         h2_rep5 = torch.bmm(self.sigmoid(h1_rep1_g), h1_rep1)\n",
    "        \n",
    "#         h1_rep7 = self.conv1_3(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "#         h1_rep7_g = self.conv2(input_seq.unsqueeze(1)).squeeze(3)\n",
    "#         h2_rep7 = torch.bmm(self.sigmoid(h1_rep1_g), h1_rep1)\n",
    "        return h2_rep3\n",
    "    def forward(self,sentence1,sentence2,length1,length2,pad1_V,pad2_V,cuda_available = False):\n",
    "        \n",
    "#         h1 = torch.mean(self.embed(sentence1),1)\n",
    "#         h1 =torch.squeeze(h1, dim=1\n",
    "#         h2 = torch.mean(self.embed(sentence2),1)\n",
    "#         h2 =torch.squeeze(h2,dim=1)\n",
    "\n",
    "        input_1 = self.embed(sentence1)\n",
    "        input_2 = self.embed(sentence2)\n",
    "        if cuda_available:\n",
    "            output_1 = torch.mul(pad1_V.float().cuda(),input_1)\n",
    "            output_2 = torch.mul(pad2_V.float().cuda(),input_2)\n",
    "        else:\n",
    "            output_1 = torch.mul(pad1_V.float(),input_1)\n",
    "            output_2 = torch.mul(pad2_V.float(),input_2)\n",
    "        represent1 = self.conv_block(output_1)\n",
    "        represent2 = self.conv_block(output_2)\n",
    "#        h1_rep1 = self.conv2_7(output_1.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "#         h1_rep1_g = self.conv2(output_1.unsqueeze(1)).squeeze(3)#.transpose(1,3)\n",
    "#         h1_rep1 = torch.mul(h1_rep1, self.sigmoid(h1_rep1_g))\n",
    "        \n",
    "#         h2_rep1 = self.conv2(h1_rep1).transpose(1,3).squeeze(1)\n",
    "#         h2_rep1_g = self.conv2_g(h1_rep1).squeeze(3)\n",
    "#         h2_rep1 = torch.bmm(self.sigmoid(h2_rep1_g), h2_rep1)\n",
    "#         represent1 = h2_rep1\n",
    "        \n",
    "#         h1_rep2 = self.conv1(output_2.unsqueeze(1)).transpose(1,3)        \n",
    "#         h1_rep2_g = self.conv1_g(output_2.unsqueeze(1)).transpose(1,3)\n",
    "#         h1_rep2 = torch.mul(h1_rep2, self.sigmoid(h1_rep2_g))\n",
    "        \n",
    "#         h2_rep2 = self.conv2(h1_rep2).transpose(1,3).squeeze(1)\n",
    "#         h2_rep2_g = self.conv2_g(h1_rep2).squeeze(3)\n",
    "#         h2_rep2 = torch.bmm(self.sigmoid(h2_rep2_g), h2_rep2)\n",
    "        \n",
    "#         out1 = self.conv2(h1.view(input_1.size()[0],1,input_1.size()[1],input_1.size()[2])).squeeze(3)\n",
    "#         out1_g = self.relu(self.conv1_g(output_1.view(input_1.size()[0],1,input_1.size()[1],input_1.size()[2])))\n",
    "#         out1_g = out1_g.transpose(1,3).squeeze(1)\n",
    "#         represent1 = torch.bmm(out1, out1_g) \n",
    "        \n",
    "#         out2 = self.conv1(output_2.view(input_2.size()[0],1,input_2.size()[1],input_2.size()[2])).squeeze(3)\n",
    "#         out2_g = self.relu(self.conv1_g(output_2.view(input_2.size()[0],1,input_2.size()[1],input_2.size()[2])))\n",
    "#         out2_g = out2_g.transpose(1,3).squeeze(1)\n",
    "#         represent2 = torch.bmm(out2, out2_g) \n",
    "        \n",
    "        output1_new = represent1.view(-1,40000)\n",
    "        output2_new = represent2.view(-1,40000)\n",
    "        mul_represent = torch.mul(output1_new,output2_new)\n",
    "        sub_represent = torch.abs(output1_new-output2_new)\n",
    "        mul_dedim = self.fc_dedim_mul(mul_represent)\n",
    "        sub_dedim = self.fc_dedim_sub(sub_represent)\n",
    "        rep1_dedim = self.fc_dedim_rep(output1_new)\n",
    "        rep2_dedim = self.fc_dedim_rep(output2_new)\n",
    "\n",
    "\n",
    "#         gate_1 = self.fc_gate(output1_new)\n",
    "#         gate_2 = self.fc_gate(output2_new)\n",
    "        \n",
    "#         re2 = torch.mul(output2_new,self.relu(gate_1))\n",
    "#         re1 = torch.mul(output1_new,self.relu(gate_2))\n",
    "#         all_rep_mul = torch.mul(re2,re1)\n",
    "        \n",
    "\n",
    "        \n",
    "#         mul_dedim = self.fc_dedim_mul(all_rep_mul)\n",
    "        \n",
    "        out_mul = self.relu(torch.cat((sub_dedim,mul_dedim,rep1_dedim,rep2_dedim),1))\n",
    "        logits  = self.fc2(self.relu(self.fc1(out_mul)))\n",
    "        return logits\n",
    "    def init_weights(self,pretrained_weight):\n",
    "        #init(self.embed.weight.data)\n",
    "        initrange = 0.001\n",
    "#         nn.init.uniform(self.embedding,a=0,b=0.00\n",
    "        self.fc1.bias.data.fill_(0)\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        #torch.nn.init.xavier_uniform(self.fc.weight.data, gain=math.sqrt(2.0))\n",
    "        #self.embed.weight.data.normal_(mean=0, std=0.01)\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.fill_(0)\n",
    "        \n",
    "        self.fcWs1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fcWs1.bias.data.fill_(0)\n",
    "        self.fcWs2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fcWs2.bias.data.fill_(0)\n",
    "    def initHidden(self,batch_size):\n",
    "        h0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "        return h0,c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class biRNN_att(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,hidden_size,output_size,n_layers = 2):\n",
    "        super(biRNN_att, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.output_size =output_size\n",
    "        self.embed= nn.Embedding(vocab_size,embedding_size)\n",
    "        self.embed_pos= nn.Embedding(len(vocabulary_pos),embedding_size)\n",
    "        self.gru= nn.GRU(input_size = self.embedding_size,\n",
    "                            hidden_size = self.hidden_size,\n",
    "                            num_layers = self.n_layers,\n",
    "                            batch_first =True,\n",
    "                            bidirectional = True)\n",
    "        self.da = 200\n",
    "        self.r = 200\n",
    "        self.fc1 = nn.Linear(100*4, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 2)\n",
    "        self.fcWs1 = nn.Linear(self.hidden_size*2, self.da)\n",
    "        self.fcWs2 = nn.Linear(self.da,self.r)\n",
    "        \n",
    "        self.conv1_3 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv1_5 = nn.Conv2d(1, 100,(5, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv1_7 = nn.Conv2d(1, 100,(7, 300), stride=(1, 300),padding=(2,0))\n",
    "#         self.conv2_3 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv2_5 = nn.Conv2d(1, 200,(5, 300), stride=(1, 300),padding=(1,0))\n",
    "        self.conv2_7 = nn.Conv2d(1, 200,(3, 300), stride=(1, 300),padding=(1,0))\n",
    "#         self.conv2_g = nn.Conv2d(1, 100,(3, 100), stride=(1, 100),padding=(1,0))\n",
    "        \n",
    "        self.fc_dedim_mul = nn.Linear(self.da*self.r,100)\n",
    "        self.fc_dedim_sub = nn.Linear(self.da*self.r,100)\n",
    "        self.fc_dedim_rep = nn.Linear(self.da*self.r,100)\n",
    "        #self.fc_gate = nn.Linear(self.hidden_size*2*self.r,self.r*self.hidden_size*2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def conv_block(self,input_seq,input_pos):\n",
    "        h1_rep3 = self.conv1_3(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "        h1_rep3_g = self.conv2_7(input_seq.unsqueeze(1)).squeeze(3)\n",
    "        h2_rep3 = torch.bmm(self.sigmoid(h1_rep3_g), h1_rep3)\n",
    "        \n",
    "#         h1_rep5 = self.self.conv1_5(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "#         h1_rep5_g = self.conv1_5(input_seq.unsqueeze(1)).squeeze(3)\n",
    "#         h2_rep5 = torch.bmm(self.sigmoid(h1_rep1_g), h1_rep1)\n",
    "        \n",
    "#         h1_rep7 = self.conv1_3(input_seq.unsqueeze(1)).transpose(1,3).squeeze(1)\n",
    "#         h1_rep7_g = self.conv2(input_seq.unsqueeze(1)).squeeze(3)\n",
    "#         h2_rep7 = torch.bmm(self.sigmoid(h1_rep1_g), h1_rep1)\n",
    "        return h2_rep3\n",
    "    def forward(self,sentence1,sentence2,sen1_pos,sen2_pos,length1,length2,pad1_V,pad2_V,cuda_available = False):\n",
    "        \n",
    "#         h1 = torch.mean(self.embed(sentence1),1)\n",
    "#         h1 =torch.squeeze(h1, dim=1\n",
    "#         h2 = torch.mean(self.embed(sentence2),1)\n",
    "#         h2 =torch.squeeze(h2,dim=1)\n",
    "        input_1_pos = self.embed_pos(sen1_pos)\n",
    "        input_2_pos = self.embed_pos(sen2_pos)\n",
    "        \n",
    "        input_1 = self.embed(sentence1)\n",
    "        input_2 = self.embed(sentence2)\n",
    "        if cuda_available:\n",
    "            output_1 = torch.mul(pad1_V.float().cuda(),input_1)\n",
    "            output_2 = torch.mul(pad2_V.float().cuda(),input_2)\n",
    "        else:\n",
    "            output_1 = torch.mul(pad1_V.float(),input_1)\n",
    "            output_2 = torch.mul(pad2_V.float(),input_2)\n",
    "        represent1 = self.conv_block(output_1,input_1_pos)\n",
    "        represent2 = self.conv_block(output_2,input_2_pos)\n",
    "        \n",
    "        output1_new = represent1.view(-1,40000)\n",
    "        output2_new = represent2.view(-1,40000)\n",
    "        mul_represent = torch.mul(output1_new,output2_new)\n",
    "        sub_represent = torch.abs(output1_new-output2_new)\n",
    "        mul_dedim = self.fc_dedim_mul(mul_represent)\n",
    "        sub_dedim = self.fc_dedim_sub(sub_represent)\n",
    "        rep1_dedim = self.fc_dedim_rep(output1_new)\n",
    "        rep2_dedim = self.fc_dedim_rep(output2_new)\n",
    "\n",
    "        out_mul = self.relu(torch.cat((sub_dedim,mul_dedim,rep1_dedim,rep2_dedim),1))\n",
    "        logits  = self.fc2(self.relu(self.fc1(out_mul)))\n",
    "        return logits\n",
    "    def init_weights(self,pretrained_weight):\n",
    "        #init(self.embed.weight.data)\n",
    "        initrange = 0.001\n",
    "#         nn.init.uniform(self.embedding,a=0,b=0.00\n",
    "        self.fc1.bias.data.fill_(0)\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "        #torch.nn.init.xavier_uniform(self.fc.weight.data, gain=math.sqrt(2.0))\n",
    "        #self.embed.weight.data.normal_(mean=0, std=0.01)\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc2.bias.data.fill_(0)\n",
    "        \n",
    "        self.fcWs1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fcWs1.bias.data.fill_(0)\n",
    "        self.fcWs2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fcWs2.bias.data.fill_(0)\n",
    "    def initHidden(self,batch_size):\n",
    "        h0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "        c0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "        return h0,c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class biRNN(nn.Module):\n",
    "#     def __init__(self,vocab_size,embedding_size,hidden_size,output_size,n_layers = 1):\n",
    "#         super(biRNN, self).__init__()\n",
    "#         self.n_layers = n_layers\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.embedding_size = embedding_size\n",
    "#         self.output_size =output_size\n",
    "#         self.embed = nn.Embedding(vocab_size,embedding_size)\n",
    "#         self.gru = nn.GRU(input_size=self.embedding_size,\n",
    "#                             hidden_size=self.hidden_size,\n",
    "#                             num_layers = self.n_layers,\n",
    "#                             batch_first =True,\n",
    "#                             bidirectional = True)\n",
    "#         self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
    "#                             hidden_size=self.hidden_size,\n",
    "#                             num_layers = self.n_layers,\n",
    "#                             batch_first =True,\n",
    "#                             bidirectional = True)\n",
    "#         self.BN0 = nn.BatchNorm1d(4800)\n",
    "#         self.BN1 = nn.BatchNorm1d(1200)\n",
    "#         self.fc1 = nn.Linear(4*self.hidden_size*2*self.n_layers*2, 1200)\n",
    "#         self.fc2 = nn.Linear(1200, 2)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.softmax = nn.Softmax()\n",
    "#     def forward(self,sentence1,sentence2,length1,length2,pad1_V,pad2_V,cuda_available = False):\n",
    "# # \n",
    "#         input_1 = self.embed(sentence1)\n",
    "#         input_2 = self.embed(sentence2)\n",
    "# #         if cuda_available:\n",
    "# #             output_1 = torch.mul(pad1_V.float().cuda(),input_1)\n",
    "# #             output_2 = torch.mul(pad2_V.float().cuda(),input_2)\n",
    "# #         else:\n",
    "# #             output_1 = torch.mul(pad1_V.float(),input_1)\n",
    "# #             output_2 = torch.mul(pad2_V.float(),input_2)\n",
    "#         output_1,hidden1 = self.gru(input_1)\n",
    "#         output_2,hidden2 = self.gru(input_2)\n",
    "        \n",
    "#         ls_o1,(ls_h1,ls_c1)= self.lstm(input_1)\n",
    "#         ls_o2,(ls_h2,ls_c2) = self.lstm(input_2)\n",
    "        \n",
    "#         A1 = torch.transpose(hidden1, 0, 1)\n",
    "#         B1 = torch.transpose(hidden2, 0, 1)\n",
    "#         A1 = A1.contiguous().view(input_1.size()[0],-1)\n",
    "#         B1 = B1.contiguous().view(input_2.size()[0],-1)\n",
    "        \n",
    "#         A2 = torch.transpose(ls_h1, 0, 1)\n",
    "#         B2 = torch.transpose(ls_h2, 0, 1)\n",
    "#         A2 = A2.contiguous().view(input_1.size()[0],-1)\n",
    "#         B2 = B2.contiguous().view(input_2.size()[0],-1)\n",
    "# #         output1 = torch.cat((output_1[:,length1,:self.hidden_size],output_1[i,0,-self.hidden_size:]), 0)\n",
    "# #         output2 = torch.cat((output_2[:,length2,:self.hidden_size],output_2[i,0,-self.hidden_size:]), 0)\n",
    "#         A = torch.cat((A1,A2), 1)\n",
    "#         B = torch.cat((B1,B2), 1)\n",
    "#         mul_represent = torch.mul(A,B)\n",
    "#         sub_represent = torch.abs(A-B)\n",
    "#         out_mul = self.relu(torch.cat((mul_represent,sub_represent,A,B),1))\n",
    "#         logits  = self.fc2(self.BN1(self.relu(self.fc1(self.BN0(out_mul)))))\n",
    "#         return logits\n",
    "#     def init_weights(self,pretrained_weight):\n",
    "#         #init(self.embed.weight.data)\n",
    "#         initrange = 0.001\n",
    "# #         nn.init.uniform(self.embedding,a=0,b=0.00\n",
    "#         self.fc1.bias.data.fill_(0)\n",
    "#         self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "#         #torch.nn.init.xavier_uniform(self.fc.weight.data, gain=math.sqrt(2.0))\n",
    "#         #self.embed.weight.data.normal_(mean=0, std=0.01)\n",
    "#         self.embed.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "#         self.fc2.weight.data.uniform_(-initrange, initrange)\n",
    "#         self.fc2.bias.data.fill_(0)\n",
    "#     def initHidden(self,batch_size):\n",
    "#         h0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "#         c0 = Variable(torch.zeros(2*self.n_layers,batch_size,self.hidden_size))\n",
    "#         return h0,c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bilstm = biRNN_att(vocab_size = np.shape(embedding_matrix)[0],embedding_size = np.shape(embedding_matrix)[1],hidden_size = 300,output_size =2,n_layers =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bilstm.init_weights(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(batch,batch_pos,hidden_num = 100,training = True):\n",
    "    length1 = [len(sen1) for sen1 in batch[:,0]]\n",
    "    length2 = [len(sen2) for sen2 in batch[:,1]]\n",
    "    max_length1 = max(length1)\n",
    "    max_length2 = max(length2)\n",
    "    #print(max_length1)\n",
    "    s1_batch = []\n",
    "    s1_batch_pos = []\n",
    "    s2_batch = []\n",
    "    s2_batch_pos = []\n",
    "    s1_batch_pad = []\n",
    "    s2_batch_pad = []\n",
    "    for sen,sen_pos in zip(batch,batch_pos):\n",
    "        if len(sen[0])==max_length1:\n",
    "            s1_batch.append(sen[0])\n",
    "            s1_batch_pad.append(np.concatenate((np.ones([len(sen[0]),hidden_num]),\n",
    "                                                np.zeros([max_length1-len(sen[0]),hidden_num])),0))\n",
    "            s1_batch_pos.append(sen_pos[0])\n",
    "        else:\n",
    "            s1_batch.append(sen[0]+(max_length1-len(sen[0]))*[0])\n",
    "            s1_batch_pos.append(sen_pos[0]+(max_length1-len(sen[0]))*[0])\n",
    "            s1_batch_pad.append(np.concatenate((np.ones([len(sen[0]),hidden_num]),\n",
    "                                                np.zeros([max_length1-len(sen[0]),hidden_num])),0))\n",
    "        if len(sen[1])==max_length2:\n",
    "            s2_batch.append(sen[1])\n",
    "            s2_batch_pos.append(sen_pos[1])\n",
    "            s2_batch_pad.append(np.concatenate((np.ones([len(sen[1]),hidden_num]),\n",
    "                                                np.zeros([max_length2-len(sen[1]),hidden_num])),0))\n",
    "        else:\n",
    "            s2_batch.append(sen[1]+(max_length2-len(sen[1]))*[0])\n",
    "            s2_batch_pos.append(sen_pos[1]+(max_length2-len(sen[1]))*[0])\n",
    "            \n",
    "            s2_batch_pad.append(np.concatenate((np.ones([len(sen[1]),hidden_num]),\n",
    "                                                np.zeros([max_length2-len(sen[1]),hidden_num])),0))\n",
    "    if training:   \n",
    "        return [Variable(torch.from_numpy(np.array(s1_batch))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch))),\n",
    "                Variable(torch.from_numpy(np.array(s1_batch_pos))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch_pos))),\n",
    "                batch[:,2].astype(int),length1,length2,\n",
    "                Variable(torch.from_numpy(np.array(s1_batch_pad))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch_pad)))]\n",
    "    else:\n",
    "        return [Variable(torch.from_numpy(np.array(s1_batch))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch))),\n",
    "                Variable(torch.from_numpy(np.array(s1_batch_pos))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch_pos))),\n",
    "                length1,length2,\n",
    "                Variable(torch.from_numpy(np.array(s1_batch_pad))),\n",
    "                Variable(torch.from_numpy(np.array(s2_batch_pad)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_s1,batch_s2,batch_s1_pos,batch_s2_pos,batch_label,length1_b,length2_b ,pad1,pad2= get_batch(np.array(data_index[0:20]),np.array(data_pos_index[0:20]),hidden_num=300,training=True)\n",
    "#o = bilstm(batch_s1,batch_s2,length1_b,length2_b,pad1,pad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o = bilstm(batch_s1,batch_s2,batch_s1_pos,batch_s2_pos,length1_b,length2_b,pad1,pad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "criterior_cross = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bilstm.parameters(), lr=1e-3)\n",
    "criterior_cross.cuda()\n",
    "bilstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_dev_size = 128\n",
    "dev_num = batch_dev_size*30\n",
    "train_data_pos = data_pos_index[:-dev_num]\n",
    "dev_data_pos = data_pos_index[-dev_num:]\n",
    "\n",
    "train_data = data_index[:-dev_num]\n",
    "dev_data = data_index[-dev_num:]\n",
    "print('train_size: '+str(len(train_data))+' dev_size: '+str(len(dev_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size =64\n",
    "best_acc = 0\n",
    "epoches = 2\n",
    "best_loss = 10\n",
    "num_model = 10\n",
    "check_file_num = range(num_model)\n",
    "step = 0\n",
    "torch_softmax= nn.Softmax()\n",
    "from sklearn.metrics import log_loss\n",
    "for epoch in range(epoches):\n",
    "    if epoch ==0:\n",
    "        check_steps =250\n",
    "    else:\n",
    "        check_steps = 50\n",
    "    #np.random.shuffle(train_data)\n",
    "    for i in range(len(train_data)/batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_s1,batch_s2,batch_s1_pos,batch_s2_pos,batch_labels,length_s1,length_s2,pad1,pad2 = get_batch(np.array(train_data[i*batch_size:(i+1)*batch_size]),\n",
    "                                                                                                           np.array(train_data_pos[i*batch_size:(i+1)*batch_size]),\n",
    "                                                                                 hidden_num=300,training=True)\n",
    "        if torch.cuda.is_available():\n",
    "            o = bilstm(batch_s1.cuda(),batch_s2.cuda(),batch_s1_pos.cuda(),batch_s2_pos.cuda(),\n",
    "                       length_s1,length_s2,pad1,pad2,cuda_available=True )  \n",
    "        loss = criterior_cross(o, Variable(torch.from_numpy(batch_labels)).cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % check_steps ==0:\n",
    "            count_correct =0\n",
    "            allsum =[]\n",
    "            pred_dev_batch = []\n",
    "            true_labels_dev = []\n",
    "            for num in range(len(dev_data)/batch_dev_size):\n",
    "                batch_s1_dev,batch_s2_dev,batch_s1_dev_pos,batch_s2_dev_pos,batch_labels_dev,length_s1_dev,length_s2_dev,pad1dev,pad2dev = get_batch(np.array(dev_data[num*batch_dev_size:(num+1)*batch_dev_size]),\n",
    "                                                                                                                   np.array(dev_data_pos[num*batch_dev_size:(num+1)*batch_dev_size]),\n",
    "                                                                                                                   hidden_num=300)\n",
    "                o = bilstm(batch_s1_dev.cuda(),batch_s2_dev.cuda(),batch_s1_dev_pos.cuda(),batch_s2_dev_pos.cuda(),\n",
    "                           length_s1_dev,length_s2_dev,pad1dev,pad2dev,cuda_available=True)\n",
    "                out_model = torch_softmax(o)\n",
    "                allsum.append(sum(out_model.data.max(1)[1].view(-1).cpu()))\n",
    "                count_correct += sum(out_model.data.max(1)[1].view(-1).cpu().numpy()==batch_labels_dev)#.cuda().long()).long().sum().data[0]\n",
    "                pred_dev_batch.extend(out_model.data.cpu().numpy()[:,1].astype(float))\n",
    "                #bi_loss = binary_log_loss(o.data[:,1],torch.from_numpy(batch_labels_dev).cuda())\n",
    "                true_labels_dev.extend(batch_labels_dev)\n",
    "                #print(bi_loss)\n",
    "            acc = count_correct/(len(dev_data)+0.0)\n",
    "            current_loss = log_loss(true_labels_dev, pred_dev_batch)\n",
    "            if current_loss<best_loss:\n",
    "                best_loss = current_loss\n",
    "                path = '/home/zhangjinbin/research/quora/model_restore/cnn_model'+str(check_file_num[step]%num_model)+'.pkl'\n",
    "                torch.save(bilstm.state_dict(), path)\n",
    "                print(\"save in : \"+ path)\n",
    "                step = step +1\n",
    "                if step==num_model:\n",
    "                    step = 0\n",
    "            print('step: '+str(i) +' acc: '+str(acc)+' '+ str(sum(allsum))+\" loss: \"+str(current_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
